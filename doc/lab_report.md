# 体系结构实习 lab2 - RISCV Simulator

## 目录

[TOC]

## 实验（开发）环境

- 操作系统：Ubuntu 18.04.4 LTS x86_64
- g++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
- GNU Make 4.1
- 交叉编译工具链riscv-gnu-toolchain，包括
  - riscv64-unknown-elf-gcc (GCC) 9.2.0
  - riscv64-unknown-elf-ar (GNU ar (GNU Binutils) 2.34)
  - riscv64-unknown-elf-objdump (GNU objdump (GNU Binutils) 2.34)

## 设计概述

该lab的要求是实现一个RISCV的功能模拟器和性能模拟器。经过思考，我认为该模拟器应具有以下的特性：

- 功能模拟和性能模拟同时实现，这样模拟的过程和结果都更接近真实的CPU，同时一份代码更利于维护和扩展
- 性能模拟的结果包括动态指令数、周期数、不同冒险导致的停顿数、分支预测准确率、缓存命中率等
- 流水线划分采用经典的五阶段流水线，即取指、译码、执行、访存和写回
- 支持RV64IMC指令集的大部分指令（FENCE和一些读写状态寄存器的指令除外）
- 自带一个精简的库，支持终端输入输出、动态内存分配、获取系统时间、随机数等
- 可深度配置不同运算、系统调用、访存等所需的周期数
- 可任意配置缓存的层次、大小、命中时间、写策略等参数
- 可配置是否启用数据前递
- 可配置不同的转移预测策略
- 支持被模拟程序的命令行参数
- 单步调试模式，支持反汇编、断点、打印寄存器、打印内存

## 具体设计和实现

### 可执行文件的装载、初始化

这部分功能对应`ElfReader`类（见`elf_reader.hpp/cpp`）。

在打开ELF文件后，借助系统库中`elf.h`（已将用到的部分放到`elf.hpp`）的ELF头、节头（section header）、程序头（program header）、符号表（symtab）以及一些辅助宏定义，可以直接用`fread`函数方便地读取ELF文件中的信息。

装载过程也比较简单，按照ELF文件中的每个程序头的信息依次将ELF文件中的内容写入内存即可。要注意的是程序头中有`filesz`和`memsz`之分，`filesz`是ELF文件中该段的内容大小，但内存中该段需要分配`memsz`的大小，多出来的部分需全设成零。

装载后的初始化工作主要包括设置PC（程序头中的`e_entry`，对应`_start`函数），初始化栈和栈指针，通用寄存器清零，流水线寄存器初始化为气泡（bubble）状态和性能计数器清零。

这里重点说一下**初始化栈**的过程。经过对`riscv64-unknown-elf-gcc`编译出来程序的分析，可以得到一个比较通用的栈布局：

```
/**
  * stack layout
  *
  * +-------------+  <--- STACK_TOP
  * | arg strings |
  * |     ...     |
  * +-------------+
  * |    NULL     |
  * +-------------+
  * | argv[argc-1]|
  * +-------------+
  * |     ...     |
  * +-------------+
  * |   argv[0]   |
  * +-------------+
  * |    argc     |
  * +-------------+  <--- sp (16 bytes aligned)
  */
```

首先按照上面的布局计算sp以及每个部分的起始地址，然后将参数字符串复制到`arg strings`中，并把起始地址放入相应的`argv[]`中，最后将参数数量放到`argc`处（注意是int类型）。要注意的一点是预留`arg strings`的空间时要考虑到每个参数字符串的结束符`\0`。

另外，为了调试方便，我借助`riscv64-unknown-elf-objdump`的输出进行反汇编，并将指令地址和汇编语句存入一个`map`中方便调试时读取和查看。

### 存储系统及其接口

这部分的功能对应`MemorySystem`类（见`memory_system.hpp/cpp`）。

主存我采用虚拟内存抽象，并采用断页式管理，每一页的大小为4KB。页表用C++标准库中的`unordered_map`维护，可以在保证性能的同时减少模拟器所需内存。

`MemorySystem`类提供的接口主要有

- `page_alloc`：按照给定的虚拟地址分配一页，并更新页表。该接口用于分配装载时所需的页以及栈和堆所需的页。
- `read_inst`：从给定的虚拟地址读取指令（4字节），返回指令内容及所需周期数
- `read_data`：从给定的虚拟地址读取数据（可指定字节数），返回数据及所需周期数
- `write_data`：在给定的虚拟地址写入数据（可指定字节数），返回所需周期数

- `sbrk`：按照给定的字节数扩展堆，该接口负责处理`sbrk`系统调用

值得留意的是读写存储系统的接口都会返回该操作所需周期数。这样的接口设计可以让模拟器核心代码无需关注存储系统的层次结构和具体构成，即缓存对于模拟器核心代码是透明的，因此缓存的配置十分灵活。

#### 缓存

现代存储系统中缓存是不可或缺的部分，而现在CPU的缓存也有非常多的配置可供选择。综合考虑下，我实现了一套踪迹驱动的可插拔、可配置的缓存系统。这部分的功能对应`Storage`类、`Cache`类和`Memory`类（见`cache.hpp/cpp`）。

`Storage`类是`Cache`类和`Memory`类的抽象父类，约定了这几个踪迹驱动模拟类的接口。由于模拟器没有必要从模拟的缓存中读取数据（因为这并不比从主存中读取更快），上述这几个类实际上接受要读或写的物理地址然后返回所需的周期数。

具体到`Cache`类，给定要读的物理地址后，它首先查找该地址对应的缓存行是否已在缓存中，如果是则返回命中所需的周期数，否则返回下一级缓存（或主存）读该地址所需的周期数，并做出相应替换（目前的替换算法是LRU）。写的情况则稍微复杂一点。如果写命中，则设置脏标志（dirty bit）并根据是否采用写回策略相应更新下一级缓存。若写不命中，则根据是否采用写分配策略做出替换或直接写下一级缓存。采用写回策略替换时也要注意检查脏标记，所需周期数也要加上写入下一级缓存的时间。`Memory`类则简单得多，无论读写都只需返回配置中访问主存所需的周期数即可。

回到存储系统的角度，读写数据和获取操作所需的周期数在模拟器代码的实现中实际上是独立的。存储系统一方面维护用于读写数据的主存页面及其页表，一方面维护用于获取周期数的踪迹驱动缓存子系统。踪迹驱动缓存子系统维护的信息包括已创建的`Cache`、指令读取入口和数据读写入口。

#### 非对齐访问

非对齐访问是一个不容易注意到的边界情况。在读写数据以及获取所需周期数的过程中，要判断读写的区间是否跨页、跨缓存行。如果跨了，则要分两次读取然后合并。

### 流水线设计

模拟器的流水线设计采用经典的五阶段流水线。流水线寄存器的定义见`register_def.hpp`。

#### IF：取指阶段

取指阶段负责选择pc、按照pc从主存或指令缓存中读取指令和预测下一个pc。

pc正常情况下就是选择根据上一条指令预测的pc，但如果

- MEM阶段的指令是分支指令（BXX）且之前预测错误，则需选择正确的跳转地址
- MEM阶段的指令是JALR指令，则需选择JALR的目标地址

虽然支持的指令集中有2字节的短指令，但是取指之前是不知道的，所以取指都取4个字节。

预测下一个pc之前需要预译码（判断该指令是否为跳转指令，并计算出直接跳转指令的跳转地址），然后根据该条指令的类型进行预测：

- 若该指令是分支指令（BXX），则交由分支预测器预测
- 若该指令是JAL指令，则预测目标地址
- 其他情况预测下一条指令

#### ID：译码阶段

译码阶段负责指令语义的解析和获取寄存器的值。指令语义的解析见[这里](#指令语义的解析)。

寄存器的值一般从寄存器堆中获取，但如果启用了数据前递且需要获取的寄存器编号rs

- 等于执行阶段的rd，则从执行阶段获取，否则如果
- 等于访存阶段的rd，则从访存阶段获取，否则如果
- 等于写回阶段的rd，则从写回阶段获取（因为真实情况下写入寄存器堆需要一定时间）

#### EX：执行阶段

执行阶段负责执行指令所需的运算。

执行运算前，需要准备ALU的两个源操作数，分以下三种情况：

- 指令对两个寄存器的值作运算，比如R-Type指令
- 指令对一个寄存器的值和立即数作运算，比如I-Type指令
- 指令对pc和立即数作运算，比如跳转指令

然后根据译码阶段得到的`alu_op`进行相应的运算。若是32位指令（后缀带w的指令），运算后还需将结果的32位进行符号扩展到64位。若是跳转指令，还需根据`funct3`判断条件是否为真。

#### MEM：访存阶段

访存阶段负责从内存中读写数据。需要注意的是读取数据后需要根据指令类型（`funct3`）进行符号扩展或零扩展。

#### WB：写回阶段

写回阶段负责将寄存器的值写入寄存器堆。需要注意的一点是当`rd==0`时不需要写回。

### 转移预测

这部分功能的代码位于`simulator.cpp`和`branch_predictor.hpp/cpp`。

转移预测包括**分支预测和跳转地址的预测**。对于**跳转地址的预测**，该模拟器通过取指阶段的预译码实现了直接跳转（BXX和JAL）的跳转地址预测。而间接跳转（JALR）由于需要读取寄存器，在不添加返回地址栈等其他辅助模块的条件下很难进行预测，因此间接跳转通过控制冒险的方式处理。

对于**分支预测**，该模拟器实现了4种分支预测器：**从不跳转，一定跳转，后跳前不跳，跳转历史表**。这4种分支预测器分别对应4个类：`NeverTaken`, `AlwaysTaken`, `BTFNT`, `BranchHistoryTable`。而这四个类都继承自下面的抽象基类：

```c++
struct BranchPredictor
{
    // next_pc即不跳转的地址，target即跳转的地址
    virtual reg_t predict(reg_t next_pc, reg_t target) const = 0;
    // 用于反馈下一条地址是next_pc的跳转语句的跳转结果
    virtual void feedback(reg_t next_pc, bool taken) {};
    // ...
};
```

这样模拟器核心代码就不需要管具体的转移预测策略，使得模拟器可扩展性更强。

几个样例程序的结果显示跳转历史表的预测正确率显著优于其他的分支预测器。

### 指令语义的解析

这部分功能的代码位于`decode_helpers.hpp/cpp`。

实际上解析指令语义的工作并不复杂，就是按照RISCV的SPEC一种一种格式，一条一条指令地去解析，在代码中的体现就是一条又一条的switch语句。因为该模拟器支持RV64C（2字节的压缩指令），所以解析指令的第一步是判断指令的最低2位是否为11，是则为4字节的正常指令，否则为2字节的压缩指令。确定指令长度后根据指令的细分类型获取指令的语义，包括

- opcode：指令功能
- funct3：指令的细分功能（在访存指令用以确定字节数和扩展方式）
- rs1，rs2，rd：源寄存器1，源寄存器2，目的寄存器（无则置0）
- imm：指令中的立即数
- alu_op：ALU要执行的运算
- compressed_inst：是否为压缩指令

值得一提的是解析指令尤其是压缩指令的过程中会经常需要将指令中的某几位提取出来再跟其他几位拼在一起，我将这个过程写成了如下的函数方便使用：

```C++
/**
 *  extract `count` bits from `start` in `inst` and left shift `shamt` bits
 */
inline uint32_t getbits(inst_t inst, int start, int count, int shamt = 0)
{
    return ((inst >> start) & ((1 << count) - 1)) << shamt;
}
```

这样**拼接立即数**就可以方便一点，比如`addi4spn`的立即数可以这样提取拼接

```c++
e.imm = getbits(inst, 5, 1, 3) | getbits(inst, 6, 1, 2) |
        getbits(inst, 7, 4, 6) | getbits(inst, 11, 2, 4);
```

### 控制信号的处理

这部分功能的代码位于`Simulator::process_control_signal()`（见`simulator.hpp/cpp`）。

得益于RISCV指令集的简单设计，RISCV五阶段流水线并没有复杂的冒险组合情况，因此控制信号的处理并不难。为了方便说明，下面用IF、ID、EX、MEM、WB分别代指流水线的取指、译码、执行、访存、写回阶段。大写字母F、D、E、M、W代表对应阶段（与前一阶段之间）的流水线寄存器，小写字母f、d、e、m、w代表（由上一阶段产生的）准备写入对应流水线寄存器的信号。

下面对每种冒险逐个分类讨论。

#### 数据冒险

数据冒险根据是否使用数据前递需要分开讨论。**不使用数据前递时**，由于最后一个阶段写回才会更新寄存器，因此只要EX、MEM和WB的目的寄存器等于ID的任一源寄存器，就产生了数据冒险。这种情况的代码如下：

```c++
data_dependent =
    (e.rs1 != 0 && (E.rd == e.rs1 || M.rd == e.rs1 || W.rd == e.rs1)) ||
    (e.rs2 != 0 && (E.rd == e.rs2 || M.rd == e.rs2 || W.rd == e.rs2));
```

**使用数据前递时**，只有LOAD指令无法及时前递，故只需处理LOAD指令的情况，代码如下：

```c++
data_dependent = (e.rs1 != 0 && e.rs1 == E.rd && E.opcode == OP_LOAD) ||
                 (e.rs2 != 0 && e.rs2 == E.rd && E.opcode == OP_LOAD);
```

数据冒险的一种特殊情况是**系统调用**，也就是ecall指令。一方面，系统调用可能访问所有寄存器，因此必须等ecall指令到达WB再处理；另一方面，系统调用可能会修改所有寄存器，因此必须暂停解码直到ecall指令处理完毕。所以判断条件为：

```c++
meet_ecall = (E.opcode == OP_ECALL || M.opcode == OP_ECALL || W.opcode == OP_ECALL);
```

**数据冒险的处理方式**是暂停解码直到寄存器的值更新，因此控制信号是IF、ID暂停（stall），EX气泡（bubble）。

#### 控制冒险

控制冒险来源于**错误的分支预测和JALR指令**。**分支指令**需要到执行阶段才能知道是否要跳转以及跳转的地址，判断条件如下：

```c++
mispredicted = false;
if (E.opcode == OP_BRANCH) {
    reg_t predPC = br_pred->predict(m.val2, m.valE);
    mispredicted = predPC != (m.cond ? m.valE : m.val2);
    // ...
}
```

其中`predPC`是之前预测的地址，`m.valE`是条件为真的跳转地址，`m.val2`则是条件为假的跳转地址，`m.cond`是条件的判断结果。判断逻辑就是看预测的地址是否与实际的地址相同。

**分支预测错误的处理方式**是取消流水线中错误的指令，因此控制信号是ID、EX气泡（因为这是下一个阶段的控制信号，实际上取消了现阶段在IF和ID的指令）。

**JALR指令**也必须等到执行阶段才能知道跳转的地址，因此判断条件是

```c++
meet_jalr = e.opcode == OP_JALR || E.opcode == OP_JALR;
```

**JALR指令冒险的处理方式**是暂停取指和解码，因此控制信号是IF暂停，ID气泡。

#### 组合冒险

仔细分析上面的判断条件，可以发现有以下几种组合冒险：

1. 不使用数据前递时，**`data_dependent`和`mispredicted`同时为真**。但由于是预测错误，ID的指令会被取消掉，因此`data_dependent`实际上不成立，因此按照转移预测错误进行处理。
2. **`meet_jalr`和`mispredicted`同时为真**。这种情况下，执行阶段是分支指令，JALR指令只能在译码阶段，同时由于预测错误，JALR指令实际上会被取消，因此按照转移预测错误进行处理。
3. **`meet_jalr`和`data_dependent`同时为真**。这种情况下，如果JALR指令在执行阶段，则译码阶段一定是气泡，不会产生数据冒险，因此JALR指令只能在译码阶段。此时数据冒险产生了，说明JALR指令的数据没准备好，因此需要暂停JALR指令的译码，也就是按照数据冒险进行处理。

### 系统调用和库函数接口的处理

我自己实现了一个迷你的库，取名为**tinylib**。库函数的头文件位于`include`目录下，库函数的实现位于`lib`目录下。模拟器处理系统调用的代码位于`Simulator::process_syscall()`（见`simulator.hpp/cpp`）。

我按照一般习惯约定系统调用号放在a7寄存器，参数放在a1-a5寄存器（所以目前最多五个参数），返回值放在a0寄存器。目前实现了如下4个系统调用：

- 程序退出
- `cputchar`：往模拟器标准输出打印a1寄存器中的字符
- `sbrk`：按照给定字节数扩展堆空间，返回新增部分的起始地址
- `readint`：在模拟器标准输入获取一个整数并返回
- `time`：返回自从Epoch以来经过的秒数

基于这些系统调用，tinylib封装了一些常用的库函数（包括终端输入输出、动态内存分配、获取系统时间、随机数，详见README的[库函数](../README.md#库函数)一节）。其中堆空间借助Splay维护，可在空间利用率和速度都有比较好的表现。在库函数的实现中，系统调用可通过一个封装的通用系统调用接口来减少内联汇编的书写：

```c
static inline int64_t
syscall(int num, uint64_t a1, uint64_t a2, uint64_t a3, uint64_t a4, uint64_t a5)
{
	int64_t ret;

	// Generic system call: pass system call number in a7,
	// up to five parameters in a1, a2, a3, a4, a5.
	// Interrupt kernel with `ecall`.
	//
	// The "volatile" tells the assembler not to optimize
	// this instruction away just because we don't use the
	// return value.
	//
	// The last clause tells the assembler that this can
	// potentially change arbitrary memory locations.

	asm volatile(
        "mv a1, %1\n"
        "mv a2, %2\n"
        "mv a3, %3\n"
        "mv a4, %4\n"
        "mv a5, %5\n"
        "li a7, %6\n"
        "ecall\n"
        "mv %0, a0"
        :   "=r" (ret)
        :   "r" (a1),
            "r" (a2),
            "r" (a3),
            "r" (a4),
            "r" (a5),
            "i" (num)
        :   "memory"
    );

	return ret;
}
```

### 性能计数相关模块的处理

目前模拟器的性能计数包括**动态指令数，周期数，分支预测准确率和缓存命中率**。动态指令数、周期数和分支预测准确率的统计主要在`simulator.cpp`中，缓存命中率则位于`cache.cpp`中。

**动态指令数的统计**需要寻找一个合适的“窗口”并注意排除流水线控制信号的影响。我选择以WB阶段为“窗口”，因为确实被执行了的指令一定会经过WB阶段，而预测错误的指令则会在WB阶段之前被取消，如此可以保证统计出来指令数的准确性。如果WB阶段是气泡或被暂停，该指令也不能被计入动态指令数。因此统计动态指令数的代码如下

```c++
instruction_count += !W.stall && !W.bubble;
```

在模拟器中**统计周期数**则与真实硬件有些不同。按照真实硬件的执行过程，模拟器应该一个周期一个周期地执行，如果遇到多周期指令则暂停直到执行完毕。这样做能十分自然地统计周期数，但实际上没有必要，因为模拟器不是真实的硬件，它并不需要真的花费这么多的“周期”来完成一个执行或访存操作。所以我在设计时，五个流水线阶段和存储系统的访存接口的返回值都是所需周期数。计算周期数时，串行的操作（比如缓存写回再读取）则将周期数相加，并行的操作（比如五个流水线阶段）则取最大值。这样的设计既可以准确地统计周期数，又可以不牺牲模拟器的效率，应该算是比较好的实践。代码示意如下

```c++
int max_cycles = 0;
max_cycles = max(max_cycles, WB());
max_cycles = max(max_cycles, MEM());
max_cycles = max(max_cycles, EX());
max_cycles = max(max_cycles, ID());
max_cycles = max(max_cycles, IF());
if (W.opcode == OP_ECALL)
    max_cycles = max(max_cycles, process_syscall());
// ...
tick += max_cycles;
```

**分支预测准确率的统计**需要统计总的分支数和预测正确的分支数。在*流水线信号处理完毕后*，若当前执行阶段的指令是分支指令，旁路寄存器`mispredicted`的值即代表该分支指令是否预测错误。因此统计代码如下

```c++
if (E.opcode == OP_BRANCH) {
    total_branch++;
    correct_branch += !mispredicted;
}
```

**缓存命中率的统计**则十分简单，只需在命中时和未命中时分别更新对应的计数器即可。

### 调试接口

该模拟器的调试功能比较简单，我将它集成在了`Simulator`类中（见`simulator.hpp`和`simulator_debugger.cpp`）。

模拟器的调试部分主要参考了gdb的设计，从中抽取了一部分常用命令。调试接口包括命令处理、断点检查和打印通用寄存器和流水线寄存器信息。断点的维护使用标准库的`set`，因此添加断点和检查断点都非常简单。命令中的表达式可以含有符号，因此需要读取ELF文件时要把符号表保存下来，计算时再查找并取出相应符号的值。

## 功能测试和性能评测

在这一章中，我会对10个程序进行功能测试和性能评测。除了该lab提供的5个样例程序外，我还测试了以下5个程序

- quick_sort：对随机生成的数列进行快速排序排序（包含正确性验证）
- ackermann：求ackermann函数（包含正确性验证）
- matrix_mul：对随机生成的矩阵做矩阵乘法（包含正确性验证）
- malloc_free：tinylib的动态内存分配压力测试（包含正确性验证）
- dhrystone：合并成一个文件的dhrystone评测程序

这5个程序都需要有输入规模作为参数。有随机性的程序还可接受指定的随机种子。为了控制无关变量，这些程序的输入规模和种子在测评时都是固定的，具体参数和种子请见`run_samples.sh`。

在下面的评测中，如果没有特别说明，所有程序

- 编译命令是`riscv64-unknown-elf-gcc -Iinclude -O2 -Wa,-march=rv64imc -static -o [output_file] [your_source_file] -Lbuild/lib -ltiny`
- 运行的配置文件都是`default_config.json`

### 动态执行指令数、周期数和平均CPI

| 程序           | 动态执行指令数 | 周期数    | 平均CPI |
| -------------- | -------------- | --------- | ------- |
| add            | 290            | 2758      | 9.510   |
| mul-div        | 312            | 2784      | 8.923   |
| n!             | 295            | 2785      | 9.441   |
| simple-fuction | 290            | 2753      | 9.493   |
| qsort          | 5397           | 8605      | 1.594   |
| quick_sort     | 18485158       | 30768959  | 1.665   |
| ackermann      | 27847017       | 32136978  | 1.154   |
| matrix_mul     | 28696552       | 42385320  | 1.477   |
| malloc_free    | 68232830       | 174963789 | 2.564   |
| dhrystone      | 42847123       | 57175525  | 1.334   |

可以看到前四个简单小程序的平均CPI显著比其他程序高，这是因为缓存预热的时间在这些小程序中占比比较大，拉高了每条指令的平均周期数。

### 冒险停顿

冒险停顿的统计需要考虑是否启用数据前递，因此测试时有两个配置文件（仅数据前递一项有区别）。

下面表格的数值代表相应冒险导致停顿或取消指令的次数。

| 程序           | 错误分支预测 | JALR冒险 | 数据冒险（数据前递） | 数据冒险（非数据前递） |
| -------------- | ------------ | -------- | -------------------- | ---------------------- |
| add            | 19           | 28       | 8                    | 229                    |
| mul-div        | 20           | 30       | 8                    | 276                    |
| n!             | 18           | 32       | 8                    | 201                    |
| simple-fuction | 19           | 28       | 8                    | 229                    |
| qsort          | 63           | 112      | 8                    | 3309                   |
| quick_sort     | 832731       | 485430   | 1096269              | 18632310               |
| ackermann      | 4133         | 2784118  | 90                   | 12528500               |
| matrix_mul     | 40668        | 60262    | 175                  | 16592584               |
| malloc_free    | 1137730      | 3153714  | 2186369              | 67974893               |
| dhrystone      | 200208       | 2007350  | 1205287              | 37225817               |

观察上面的结果我们可以得出以下结论：

- 启用数据前递能大大减少数据冒险导致的停顿（一般情况下也能少大概两个数量级）
- 对于quick_sort和malloc_free这类if判断比较多、算法较复杂的程序错误分支预测会比较多
- 对于ackermann和dhrystone这类函数（递归）调用较多的程序，JALR冒险比较多（因JALR指令通常用于函数返回）

### 分支预测

分支预测准确率的统计需要考虑使用哪种分支预测策略。实际测评时，我对所有模拟器支持的4中分支预测策略都进行了测评，因此有四个配置文件（仅分支预测策略一项不同）。

下面表格的数值代表预测正确率。

| 程序           | 从不跳转 | 总是跳转 | 后跳前不跳 | 跳转历史表 |
| -------------- | -------- | -------- | ---------- | ---------- |
| add            | 46.341%  | 53.659%  | 58.537%    | 53.659%    |
| mul-div        | 47.619%  | 52.381%  | 57.143%    | 52.381%    |
| n!             | 43.902%  | 56.098%  | 56.098%    | 56.098%    |
| simple-fuction | 46.341%  | 53.659%  | 58.537%    | 53.659%    |
| qsort          | 50.901%  | 49.099%  | 94.364%    | 96.339%    |
| quick_sort     | 55.382%  | 44.618%  | 58.102%    | 83.826%    |
| ackermann      | 66.602%  | 33.398%  | 33.400%    | 99.901%    |
| matrix_mul     | 1.246%   | 98.754%  | 99.001%    | 99.001%    |
| malloc_free    | 48.868%  | 51.132%  | 58.338%    | 81.560%    |
| dhrystone      | 58.330%  | 41.670%  | 62.538%    | 95.834%    |

从上表可以看出，从不跳转和总是跳转策略各有优劣，后跳前不跳策略总体比前两个策略稍好，跳转历史表在有一定运行时长的程序中都显著比其他三种策略优，因此不难理解现代CPU基本上都采用基于历史的预测策略。

### 缓存不命中率

| 程序           | L1指令(48KB) | L1数据(32KB) | L2 (512KB) | L3 (8192KB) |
| -------------- | ------------ | ------------ | ---------- | ----------- |
| add            | 3.916%       | 9.901%       | 100.000%   | 100.000%    |
| mul-div        | 3.893%       | 9.901%       | 100.000%   | 100.000%    |
| n!             | 3.827%       | 11.111%      | 100.000%   | 100.000%    |
| simple-fuction | 4.233%       | 9.901%       | 100.000%   | 100.000%    |
| qsort          | 0.314%       | 1.054%       | 100.000%   | 100.000%    |
| quick_sort     | 0.000%       | 1.579%       | 32.607%    | 19.786%     |
| ackermann      | 0.000%       | 0.010%       | 96.707%    | 100.000%    |
| matrix_mul     | 0.000%       | 6.350%       | 1.513%     | 43.500%     |
| malloc_free    | 0.000%       | 1.630%       | 50.871%    | 35.823%     |
| dhrystone      | 0.000%       | 0.001%       | 100.000%   | 100.000%    |

从上表的数据我们可以得到一些结论：

- 对于有一定运行时长的程序，L1指令缓存基本不会miss，可见指令缓存单独分出来可以显著减少取指所需耗费的时间
- 对于空间局部性很好的程序，由于数据基本上都在L1中，会导致L2和L3基本上都是冷不命中，导致不命中率非常高

## 开源库

在这里特别感谢开源库[nlohmann/json](https://github.com/nlohmann/json)帮我完成JSON文件的解析工作。
